{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyodbc.Cursor at 0x26831094030>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB = {'servername': 'LAPTOP-LPE28RPE\\SQLEXPRESS', \n",
    "    'database': 'United_outdoors'}\n",
    "\n",
    "export_conn = pyodbc.connect('DRIVER={SQL Server};SERVER=' + DB['servername'] + \n",
    "                              ';DATABASE=' + DB['database'])\n",
    "\n",
    "export_cursor = export_conn.cursor()\n",
    "export_cursor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Adventure = {\n",
    "    'servername' : 'LAPTOP-LPE28RPE\\SQLEXPRESS',\n",
    "    'database' : 'AdventureWorks2019'\n",
    "}\n",
    "\n",
    "\n",
    "Northwind = {\n",
    "    'servername' : 'LAPTOP-LPE28RPE\\SQLEXPRESS',\n",
    "    'database' : 'Northwind'\n",
    "}\n",
    "\n",
    "access_db_path =  r'C:\\Users\\Humberto de Castro\\OneDrive\\Desktop\\SEM4\\AenC\\aenc.accdb'\n",
    "\n",
    "#Connect to AdventureWorks\n",
    "Adventure_conn = pyodbc.connect(f\"DRIVER={{SQL Server}};SERVER={Adventure['servername']};DATABASE={Adventure['database']};Trusted_Connection=yes;\")\n",
    "Adventure_cursor = Adventure_conn.cursor()\n",
    "\n",
    "#Connect to Northwind\n",
    "Northwind_conn = pyodbc.connect(f\"DRIVER={{SQL Server}};SERVER={Northwind['servername']};DATABASE={Northwind['database']};Trusted_Connection=yes;\")\n",
    "Northwind_cursor = Northwind_conn.cursor()\n",
    "\n",
    "#Connect to AenC\n",
    "AenC_conn = pyodbc.connect(f\"DRIVER={{Microsoft Access Driver (*.mdb, *.accdb)}};DBQ={access_db_path};\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Humberto de Castro\\AppData\\Local\\Temp\\ipykernel_95804\\3836312607.py:34: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dataframes[table_name] = pd.read_sql_query(query, Adventure_conn)\n",
      "C:\\Users\\Humberto de Castro\\AppData\\Local\\Temp\\ipykernel_95804\\3836312607.py:37: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dataframes[table_name] = pd.read_sql_query(query, Northwind_conn)\n",
      "C:\\Users\\Humberto de Castro\\AppData\\Local\\Temp\\ipykernel_95804\\3836312607.py:40: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dataframes[table_name] = pd.read_sql_query(query, AenC_conn)\n"
     ]
    }
   ],
   "source": [
    "AdventureWorks_queries = {\n",
    "    'AW_Employee' : 'SELECT * FROM HumanResources.Employee',\n",
    "    'Person' : 'SELECT * FROM Person.Person',\n",
    "    'BusinessEntity' : 'SELECT * FROM Person.BusinessEntity',\n",
    "    'BusinessEntityAddress' : 'SELECT * FROM Person.BusinessEntityAddress',\n",
    "    'PersonAddress' : 'SELECT * FROM Person.Address',\n",
    "    'StateProvince' : 'SELECT * FROM Person.StateProvince',\n",
    "    'CountryRegion' : 'SELECT * FROM Person.CountryRegion',\n",
    "    'Territory' : 'SELECT * FROM Sales.SalesTerritory',\n",
    "    'Department' : 'SELECT * FROM HumanResources.EmployeeDepartmentHistory'\n",
    "    \n",
    "}\n",
    "\n",
    "Northwind_queries = {\n",
    "    'NW_Employee' : 'SELECT * FROM Employees',\n",
    "    'EmployeeTerritories' : 'SELECT * FROM EmployeeTerritories',\n",
    "    'NW_Territories' : 'SELECT * FROM Territories',\n",
    "    'NW_Region' : 'SELECT * FROM Region',\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "AenC_queries = {\n",
    "    'AC_Employee' : 'SELECT * FROM Employee',\n",
    "    'state' : 'SELECT * FROM state'\n",
    "    \n",
    "}\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "# Lees elke tabel in een DataFrame\n",
    "\n",
    "for table_name, query in AdventureWorks_queries.items():\n",
    "    dataframes[table_name] = pd.read_sql_query(query, Adventure_conn)\n",
    "\n",
    "for table_name, query in Northwind_queries.items():\n",
    "    dataframes[table_name] = pd.read_sql_query(query, Northwind_conn)\n",
    "\n",
    "for table_name, query in AenC_queries.items():\n",
    "    dataframes[table_name] = pd.read_sql_query(query, AenC_conn)\n",
    "\n",
    "#als je ik elk tabel als een dataframe/ variabele wil behandelen of aanroepen moet ik dit uitvoeren.\n",
    "for table_name, df in dataframes.items():\n",
    "    globals()[table_name] = df\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adventureworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BusinessEntityID', 'NationalIDNumber', 'LoginID', 'OrganizationNode',\n",
      "       'OrganizationLevel', 'JobTitle', 'BirthDate', 'MaritalStatus', 'Gender',\n",
      "       'HireDate', 'SalariedFlag', 'VacationHours', 'SickLeaveHours',\n",
      "       'CurrentFlag', 'PersonType', 'NameStyle', 'Title', 'FirstName',\n",
      "       'MiddleName', 'LastName', 'Suffix', 'EmailPromotion',\n",
      "       'AdditionalContactInfo', 'Demographics', 'AddressID', 'AddressTypeID',\n",
      "       'AddressLine1', 'AddressLine2', 'City', 'StateProvinceID', 'PostalCode',\n",
      "       'SpatialLocation', 'StateProvinceCode', 'CountryRegionCode',\n",
      "       'IsOnlyStateProvinceFlag', 'Name', 'TerritoryID', 'Name_countryregion',\n",
      "       'Name_Territory', 'CountryRegionCode_Territory', 'Group', 'SalesYTD',\n",
      "       'SalesLastYear', 'CostYTD', 'CostLastYear', 'DepartmentID', 'ShiftID',\n",
      "       'StartDate', 'EndDate', 'ModifiedDate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming AW_Employee, Person, BusinessEntityAddress, PersonAddress, StateProvince, CountryRegion, and Territory are already defined DataFrames\n",
    "\n",
    "# Drop columns 'rowguid' and 'ModifiedDate' from each DataFrame\n",
    "columns_to_drop = ['rowguid', 'ModifiedDate']\n",
    "\n",
    "AW_Employee = AW_Employee.drop(columns=[col for col in columns_to_drop if col in AW_Employee.columns])\n",
    "Person = Person.drop(columns=[col for col in columns_to_drop if col in Person.columns])\n",
    "BusinessEntityAddress = BusinessEntityAddress.drop(columns=[col for col in columns_to_drop if col in BusinessEntityAddress.columns])\n",
    "PersonAddress = PersonAddress.drop(columns=[col for col in columns_to_drop if col in PersonAddress.columns])\n",
    "StateProvince = StateProvince.drop(columns=[col for col in columns_to_drop if col in StateProvince.columns])\n",
    "CountryRegion = CountryRegion.drop(columns=[col for col in columns_to_drop if col in CountryRegion.columns])\n",
    "Territory = Territory.drop(columns=[col for col in columns_to_drop if col in Territory.columns])\n",
    "\n",
    "\n",
    "# Merge AW_Employee with Person, add suffixes to avoid duplicate columns\n",
    "AW_Employee = pd.merge(AW_Employee, Person, on='BusinessEntityID')\n",
    "\n",
    "# Merge the result with BusinessEntityAddress, add suffixes to avoid duplicate columns\n",
    "AW_Employee = pd.merge(AW_Employee, BusinessEntityAddress, on='BusinessEntityID', suffixes=('', '_business'))\n",
    "\n",
    "# Merge the result with PersonAddress, add suffixes to avoid duplicate columns\n",
    "AW_Employee = pd.merge(AW_Employee, PersonAddress, left_on='AddressID', right_on='AddressID', suffixes=('', '_personaddress'))\n",
    "\n",
    "# Merge the result with StateProvince, add suffixes to avoid duplicate columns\n",
    "AW_Employee = pd.merge(AW_Employee, StateProvince, left_on='StateProvinceID', right_on='StateProvinceID', suffixes=('', '_stateprovince'))\n",
    "\n",
    "# Merge the result with CountryRegion, add suffixes to avoid duplicate columns\n",
    "AW_Employee = pd.merge(AW_Employee, CountryRegion, left_on='CountryRegionCode', right_on='CountryRegionCode', suffixes=('', '_countryregion'))\n",
    "\n",
    "# Merge the result with Territory, add suffixes to avoid duplicate columns\n",
    "AW_Employee = pd.merge(AW_Employee, Territory, left_on='TerritoryID', right_on='TerritoryID', suffixes = ('', '_Territory'))\n",
    "\n",
    "#We hebben departmentID nodig:\n",
    "AW_Employee = pd.merge(AW_Employee, Department, on = 'BusinessEntityID')\n",
    "\n",
    "\n",
    "print(AW_Employee.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Years in service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure HireDate is in datetime format\n",
    "AW_Employee['HireDate'] = pd.to_datetime(AW_Employee['HireDate'], errors='coerce')\n",
    "\n",
    "# Calculate the number of years in service\n",
    "current_date = datetime.now()\n",
    "AW_Employee['Years_in_Service'] = AW_Employee['HireDate'].apply(lambda x: current_date.year - x.year - ((current_date.month, current_date.day) < (x.month, x.day)) if pd.notnull(x) else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Northwind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary for replacements\n",
    "replacement_dict = {\n",
    "    'Mr.': 'M',\n",
    "    'Dr.': 'M',\n",
    "    'Ms.': 'F',\n",
    "    'Mrs.': 'F',\n",
    "    'Miss': 'F'\n",
    "}\n",
    "\n",
    "# Replace 'USA' with 'US' in the Country column\n",
    "NW_Employee['Country'] = NW_Employee['Country'].replace('USA', 'US')\n",
    "\n",
    "# Replace TitleOfCourtesy based on the dictionary\n",
    "NW_Employee['TitleOfCourtesy'] = NW_Employee['TitleOfCourtesy'].replace(replacement_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmployeeID   LastName FirstName                     Title TitleOfCourtesy  \\\n",
      "0          1    Davolio     Nancy      Sales Representative               F   \n",
      "1          2     Fuller    Andrew     Vice President, Sales               M   \n",
      "2          3  Leverling     Janet      Sales Representative               F   \n",
      "3          4    Peacock  Margaret      Sales Representative               F   \n",
      "4          5   Buchanan    Steven             Sales Manager               M   \n",
      "5          6     Suyama   Michael      Sales Representative               M   \n",
      "6          7       King    Robert      Sales Representative               M   \n",
      "7          8   Callahan     Laura  Inside Sales Coordinator               F   \n",
      "8          9  Dodsworth      Anne      Sales Representative               F   \n",
      "\n",
      "   BirthDate   HireDate                         Address      City Region  ...  \\\n",
      "0 1948-12-08 1992-05-01       507 - 20th Ave. E.Apt. 2A   Seattle     WA  ...   \n",
      "1 1952-02-19 1992-08-14              908 W. Capital Way    Tacoma     WA  ...   \n",
      "2 1963-08-30 1992-04-01              722 Moss Bay Blvd.  Kirkland     WA  ...   \n",
      "3 1937-09-19 1993-05-03            4110 Old Redmond Rd.   Redmond     WA  ...   \n",
      "4 1955-03-04 1993-10-17                 14 Garrett Hill    London   None  ...   \n",
      "5 1963-07-02 1993-10-17       Coventry House\\nMiner Rd.    London   None  ...   \n",
      "6 1960-05-29 1994-01-02  Edgeham Hollow\\nWinchester Way    London   None  ...   \n",
      "7 1958-01-09 1994-03-05           4726 - 11th Ave. N.E.   Seattle     WA  ...   \n",
      "8 1966-01-27 1994-11-15               7 Houndstooth Rd.    London   None  ...   \n",
      "\n",
      "        HomePhone Extension  \\\n",
      "0  (206) 555-9857      5467   \n",
      "1  (206) 555-9482      3457   \n",
      "2  (206) 555-3412      3355   \n",
      "3  (206) 555-8122      5176   \n",
      "4   (71) 555-4848      3453   \n",
      "5   (71) 555-7773       428   \n",
      "6   (71) 555-5598       465   \n",
      "7  (206) 555-1189      2344   \n",
      "8   (71) 555-4444       452   \n",
      "\n",
      "                                               Photo  \\\n",
      "0  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "1  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "2  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "3  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "4  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "5  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "6  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "7  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "8  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "\n",
      "                                               Notes ReportsTo  \\\n",
      "0  Education includes a BA in psychology from Col...       2.0   \n",
      "1  Andrew received his BTS commercial in 1974 and...       NaN   \n",
      "2  Janet has a BS degree in chemistry from Boston...       2.0   \n",
      "3  Margaret holds a BA in English literature from...       2.0   \n",
      "4  Steven Buchanan graduated from St. Andrews Uni...       2.0   \n",
      "5  Michael is a graduate of Sussex University (MA...       5.0   \n",
      "6  Robert King served in the Peace Corps and trav...       5.0   \n",
      "7  Laura received a BA in psychology from the Uni...       2.0   \n",
      "8  Anne has a BA degree in English from St. Lawre...       5.0   \n",
      "\n",
      "                                PhotoPath  TerritoryID RegionID  \\\n",
      "0    http://accweb/emmployees/davolio.bmp        19713        1   \n",
      "1     http://accweb/emmployees/fuller.bmp        40222        1   \n",
      "2  http://accweb/emmployees/leverling.bmp        33607        4   \n",
      "3    http://accweb/emmployees/peacock.bmp        27511        1   \n",
      "4   http://accweb/emmployees/buchanan.bmp        14450        1   \n",
      "5    http://accweb/emmployees/davolio.bmp        98104        2   \n",
      "6    http://accweb/emmployees/davolio.bmp        95060        2   \n",
      "7    http://accweb/emmployees/davolio.bmp        53404        3   \n",
      "8    http://accweb/emmployees/davolio.bmp        55439        3   \n",
      "\n",
      "                                TerritoryDescription  \\\n",
      "0  Neward                                        ...   \n",
      "1  Louisville                                    ...   \n",
      "2  Tampa                                         ...   \n",
      "3  Cary                                          ...   \n",
      "4  Fairport                                      ...   \n",
      "5  Seattle                                       ...   \n",
      "6  Santa Cruz                                    ...   \n",
      "7  Racine                                        ...   \n",
      "8  Minneapolis                                   ...   \n",
      "\n",
      "                                   RegionDescription  \n",
      "0  Eastern                                       ...  \n",
      "1  Eastern                                       ...  \n",
      "2  Southern                                      ...  \n",
      "3  Eastern                                       ...  \n",
      "4  Eastern                                       ...  \n",
      "5  Western                                       ...  \n",
      "6  Western                                       ...  \n",
      "7  Northern                                      ...  \n",
      "8  Northern                                      ...  \n",
      "\n",
      "[9 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'EmployeeID', 'TerritoryID', and 'RegionID' are the same type (string) in all DataFrames\n",
    "NW_Employee['EmployeeID'] = NW_Employee['EmployeeID'].astype(str)\n",
    "EmployeeTerritories['EmployeeID'] = EmployeeTerritories['EmployeeID'].astype(str)\n",
    "NW_Territories['TerritoryID'] = NW_Territories['TerritoryID'].astype(str)\n",
    "NW_Region['RegionID'] = NW_Region['RegionID'].astype(str)\n",
    "\n",
    "# Drop duplicates, keeping the last entry for each 'EmployeeID'\n",
    "unique_employee_territories = EmployeeTerritories.drop_duplicates(subset='EmployeeID', keep='last')\n",
    "\n",
    "# Merge NW_Employee with unique_employee_territories to add TerritoryID\n",
    "NW_Employee = pd.merge(NW_Employee, unique_employee_territories[['EmployeeID', 'TerritoryID']], on='EmployeeID', suffixes=('', '_EmployeeTerritory'))\n",
    "\n",
    "# Ensure 'TerritoryID' and 'RegionID' are the same type before merging\n",
    "NW_Employee['TerritoryID'] = NW_Employee['TerritoryID'].astype(str)\n",
    "NW_Territories['TerritoryID'] = NW_Territories['TerritoryID'].astype(str)\n",
    "\n",
    "# Merge NW_Employee with NW_Territories to add RegionID and TerritoryDescription\n",
    "NW_Employee = pd.merge(NW_Employee, NW_Territories[['TerritoryID', 'RegionID', 'TerritoryDescription']], on='TerritoryID', suffixes=('', '_Territory'))\n",
    "\n",
    "# Ensure 'RegionID' is the same type before merging\n",
    "NW_Employee['RegionID'] = NW_Employee['RegionID'].astype(str)\n",
    "NW_Region['RegionID'] = NW_Region['RegionID'].astype(str)\n",
    "\n",
    "# Merge NW_Employee with NW_Region to add RegionDescription\n",
    "NW_Employee = pd.merge(NW_Employee, NW_Region[['RegionID', 'RegionDescription']], on='RegionID', suffixes=('', '_Region'))\n",
    "\n",
    "# Ensure the final DataFrame has unique employees\n",
    "NW_Employee = NW_Employee.drop_duplicates(subset='EmployeeID', keep='last')\n",
    "\n",
    "# Print the final merged DataFrame\n",
    "print(NW_Employee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Years in service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse mixed date formats\n",
    "def parse_date(date_str):\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format='%d-%b-%Y %I:%M:%S %p', errors='coerce')\n",
    "    except ValueError:\n",
    "        return pd.to_datetime(date_str, errors='coerce')\n",
    "\n",
    "# Apply the parse_date function to the Hire_date column\n",
    "NW_Employee['HireDate'] = NW_Employee['HireDate'].apply(parse_date)\n",
    "\n",
    "# Calculate the number of years in service\n",
    "current_date = datetime.now()\n",
    "NW_Employee['Years_in_Service'] = NW_Employee['HireDate'].apply(lambda x: current_date.year - x.year - ((current_date.month, current_date.day) < (x.month, x.day)) if pd.notnull(x) else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AenC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AC_Employee = pd.merge(AC_Employee, state, left_on= 'state', right_on= 'state_id')\n",
    "\n",
    "# Replace 'USA' with 'US' in the Country column\n",
    "AC_Employee['country'] = AC_Employee['country'].replace('USA', 'US')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emp_id manager_id  emp_fname   emp_lname dept_id  \\\n",
      "0     102        501       Fran     Whitney     100   \n",
      "1     105        501    Matthew        Cobb     100   \n",
      "2     129        902     Philip        Chin     200   \n",
      "3     148       1293      Julie      Jordan     300   \n",
      "4     160        501     Robert     Breault     100   \n",
      "..    ...        ...        ...         ...     ...   \n",
      "70   1643       1576  Elizabeth     Lambert     400   \n",
      "71   1658        703    Michael       Lynch     500   \n",
      "72   1684       1576      Janet  Hildebrand     400   \n",
      "73   1740       1576     Robert     Nielsen     400   \n",
      "74   1751       1576       Alex       Ahmed     400   \n",
      "\n",
      "                       street        city state zip_code       phone  ...  \\\n",
      "0   49 East Washington Street     Needham    MA    02192  6175553985  ...   \n",
      "1          77 Pleasant Street     Waltham    MA    02154  6175553840  ...   \n",
      "2              59 Pond Street     Atlanta    GA    30339  4045552341  ...   \n",
      "3      144 Great Plain Avenue  Winchester    MA    01890  6175557835  ...   \n",
      "4            58 Cherry Street      Milton    MA    02186  6175553099  ...   \n",
      "..                        ...         ...   ...      ...         ...  ...   \n",
      "70            29 Union Street  Burlington    MA    01803  6175552357  ...   \n",
      "71          76 Brookside Road     Waltham    MA    02154  6175558348  ...   \n",
      "72          47 Hilltop Street     Waltham    MA    02154  6175553845  ...   \n",
      "73          55 Sargent Avenue     Bedford    MA    01730  6175558757  ...   \n",
      "74         114 Cushing Street     Needham    MA    02192  6175558748  ...   \n",
      "\n",
      "   bene_health_ins bene_life_ins bene_day_care sex state_id     state_name  \\\n",
      "0                Y             Y             N   F       MA  Massachusetts   \n",
      "1                Y             Y             N   M       MA  Massachusetts   \n",
      "2                Y             Y             N   M       GA        Georgia   \n",
      "3                Y             Y             N   F       MA  Massachusetts   \n",
      "4                Y             Y             Y   M       MA  Massachusetts   \n",
      "..             ...           ...           ...  ..      ...            ...   \n",
      "70               Y             Y             N   F       MA  Massachusetts   \n",
      "71               Y             Y             N   M       MA  Massachusetts   \n",
      "72               Y             Y             N   F       MA  Massachusetts   \n",
      "73               Y             Y             N   M       MA  Massachusetts   \n",
      "74               Y             Y             N   M       MA  Massachusetts   \n",
      "\n",
      "   state_capital country   region Job_title  \n",
      "0         Boston      US  Eastern       NaN  \n",
      "1         Boston      US  Eastern       NaN  \n",
      "2        Atlanta      US    South       NaN  \n",
      "3         Boston      US  Eastern       NaN  \n",
      "4         Boston      US  Eastern       NaN  \n",
      "..           ...     ...      ...       ...  \n",
      "70        Boston      US  Eastern       NaN  \n",
      "71        Boston      US  Eastern       NaN  \n",
      "72        Boston      US  Eastern       NaN  \n",
      "73        Boston      US  Eastern       NaN  \n",
      "74        Boston      US  Eastern       NaN  \n",
      "\n",
      "[75 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "manager_df = pd.DataFrame(AC_Employee)\n",
    "\n",
    "# Extract unique manager IDs\n",
    "manager_ids = manager_df['manager_id'].unique()\n",
    "\n",
    "# Update Job_title to 'Manager' for employees who are managers\n",
    "AC_Employee.loc[AC_Employee['emp_id'].isin(manager_ids.astype(str)), 'Job_title'] = 'Manager'\n",
    "\n",
    "print(AC_Employee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Years in service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse mixed date formats\n",
    "def parse_date(date_str):\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format='%d-%b-%Y %I:%M:%S %p', errors='coerce')\n",
    "    except ValueError:\n",
    "        return pd.to_datetime(date_str, errors='coerce')\n",
    "\n",
    "# Apply the parse_date function to the Hire_date column\n",
    "AC_Employee['start_date'] = AC_Employee['start_date'].apply(parse_date)\n",
    "\n",
    "# Calculate the number of years in service\n",
    "current_date = datetime.now()\n",
    "AC_Employee['Years_in_Service'] = AC_Employee['start_date'].apply(lambda x: current_date.year - x.year - ((current_date.month, current_date.day) < (x.month, x.day)) if pd.notnull(x) else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "AW_Employee.rename(columns={\n",
    "    'BusinessEntityID': 'EmployeeID',\n",
    "    'Group' : 'Region',\n",
    "    'CountryRegionCode' : 'Country',\n",
    "    'StateProvinceCode' : 'State',\n",
    "    'AddressLine1' : 'Address',\n",
    "    'JobTitle' : 'Job_title',\n",
    "    'BirthDate' : 'Birth_date',\n",
    "    'HireDate': 'Hire_date'\n",
    "\n",
    "}, inplace=True)\n",
    "\n",
    "# change shipvia to string \n",
    "#Northwind_Order['ShipVia'] = Northwind_Order['ShipVia'].astype(str)\n",
    "NW_Employee.rename(columns={\n",
    "    'Title': 'Job_title',\n",
    "    'RegionDescription' : 'Region',\n",
    "    'Region' : 'State',\n",
    "    'BirthDate' : 'Birth_date',\n",
    "    'HireDate': 'Hire_date',\n",
    "    'TitleOfCourtesy' : 'Gender'\n",
    "    \n",
    "}, inplace=True)\n",
    "\n",
    "AC_Employee.rename(columns={\n",
    "    'emp_id': 'EmployeeID',\n",
    "    'emp_fname': 'FirstName',\n",
    "    'emp_lname': 'LastName',\n",
    "    'region' : 'Region', \n",
    "    'country' : 'Country',\n",
    "    'state': 'State',\n",
    "    'city': 'City',\n",
    "    'zip_code': 'PostalCode',\n",
    "    'street': 'Address',\n",
    "    'dept_id' : 'DepartmentID',\n",
    "    'birth_date' : 'Birth_date',\n",
    "    'start_date': 'Hire_date',\n",
    "    'sex' : 'Gender',\n",
    "    \n",
    "}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AW regions aanpassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the 'Region' field for 'AW' employees where Region is 'North America' to 'Northern'\n",
    "AW_Employee.loc[AW_Employee['Region'] == 'North America', 'Region'] = 'Northern'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Northwind London locations aanpassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmployeeID   LastName FirstName                 Job_title Gender Birth_date  \\\n",
      "0          1    Davolio     Nancy      Sales Representative      F 1948-12-08   \n",
      "1          2     Fuller    Andrew     Vice President, Sales      M 1952-02-19   \n",
      "2          3  Leverling     Janet      Sales Representative      F 1963-08-30   \n",
      "3          4    Peacock  Margaret      Sales Representative      F 1937-09-19   \n",
      "4          5   Buchanan    Steven             Sales Manager      M 1955-03-04   \n",
      "5          6     Suyama   Michael      Sales Representative      M 1963-07-02   \n",
      "6          7       King    Robert      Sales Representative      M 1960-05-29   \n",
      "7          8   Callahan     Laura  Inside Sales Coordinator      F 1958-01-09   \n",
      "8          9  Dodsworth      Anne      Sales Representative      F 1966-01-27   \n",
      "\n",
      "   Hire_date                         Address      City State  ... Extension  \\\n",
      "0 1992-05-01       507 - 20th Ave. E.Apt. 2A   Seattle    WA  ...      5467   \n",
      "1 1992-08-14              908 W. Capital Way    Tacoma    WA  ...      3457   \n",
      "2 1992-04-01              722 Moss Bay Blvd.  Kirkland    WA  ...      3355   \n",
      "3 1993-05-03            4110 Old Redmond Rd.   Redmond    WA  ...      5176   \n",
      "4 1993-10-17                 14 Garrett Hill    London   ENG  ...      3453   \n",
      "5 1993-10-17       Coventry House\\nMiner Rd.    London   ENG  ...       428   \n",
      "6 1994-01-02  Edgeham Hollow\\nWinchester Way    London   ENG  ...       465   \n",
      "7 1994-03-05           4726 - 11th Ave. N.E.   Seattle    WA  ...      2344   \n",
      "8 1994-11-15               7 Houndstooth Rd.    London   ENG  ...       452   \n",
      "\n",
      "                                               Photo  \\\n",
      "0  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "1  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "2  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "3  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "4  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "5  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "6  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "7  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "8  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "\n",
      "                                               Notes ReportsTo  \\\n",
      "0  Education includes a BA in psychology from Col...       2.0   \n",
      "1  Andrew received his BTS commercial in 1974 and...       NaN   \n",
      "2  Janet has a BS degree in chemistry from Boston...       2.0   \n",
      "3  Margaret holds a BA in English literature from...       2.0   \n",
      "4  Steven Buchanan graduated from St. Andrews Uni...       2.0   \n",
      "5  Michael is a graduate of Sussex University (MA...       5.0   \n",
      "6  Robert King served in the Peace Corps and trav...       5.0   \n",
      "7  Laura received a BA in psychology from the Uni...       2.0   \n",
      "8  Anne has a BA degree in English from St. Lawre...       5.0   \n",
      "\n",
      "                                PhotoPath TerritoryID  RegionID  \\\n",
      "0    http://accweb/emmployees/davolio.bmp       19713         1   \n",
      "1     http://accweb/emmployees/fuller.bmp       40222         1   \n",
      "2  http://accweb/emmployees/leverling.bmp       33607         4   \n",
      "3    http://accweb/emmployees/peacock.bmp       27511         1   \n",
      "4   http://accweb/emmployees/buchanan.bmp       14450         1   \n",
      "5    http://accweb/emmployees/davolio.bmp       98104         2   \n",
      "6    http://accweb/emmployees/davolio.bmp       95060         2   \n",
      "7    http://accweb/emmployees/davolio.bmp       53404         3   \n",
      "8    http://accweb/emmployees/davolio.bmp       55439         3   \n",
      "\n",
      "                                TerritoryDescription  \\\n",
      "0  Neward                                        ...   \n",
      "1  Louisville                                    ...   \n",
      "2  Tampa                                         ...   \n",
      "3  Cary                                          ...   \n",
      "4  Fairport                                      ...   \n",
      "5  Seattle                                       ...   \n",
      "6  Santa Cruz                                    ...   \n",
      "7  Racine                                        ...   \n",
      "8  Minneapolis                                   ...   \n",
      "\n",
      "                                              Region Years_in_Service  \n",
      "0  Eastern                                       ...               32  \n",
      "1  Eastern                                       ...               31  \n",
      "2  Southern                                      ...               32  \n",
      "3  Eastern                                       ...               31  \n",
      "4  Eastern                                       ...               30  \n",
      "5  Western                                       ...               30  \n",
      "6  Western                                       ...               30  \n",
      "7  Northern                                      ...               30  \n",
      "8  Northern                                      ...               29  \n",
      "\n",
      "[9 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to update 'State' and 'Country' for employees in London\n",
    "def update_london_employees(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if row['City'] == 'London':\n",
    "            df.at[index, 'State'] = 'ENG'\n",
    "            df.at[index, 'Country'] = 'GB'\n",
    "    return df\n",
    "\n",
    "# Update the NW_Employee DataFrame\n",
    "NW_Employee = update_london_employees(NW_Employee)\n",
    "\n",
    "# Print the updated DataFrame to check the changes\n",
    "print(NW_Employee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AenC Region aanpassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the 'Region' field for 'AC' employees where Region is 'South' to 'Southern'\n",
    "AC_Employee.loc[AC_Employee['Region'] == 'South', 'Region'] = 'Southern'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prefix voor employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a prefix to EmployeeIDs for each source DataFrame\n",
    "AW_Employee['EmployeeID'] = AW_Employee['EmployeeID'].apply(lambda x: f'AW_{x}')\n",
    "NW_Employee['EmployeeID'] = NW_Employee['EmployeeID'].apply(lambda x: f'NW_{x}')\n",
    "AC_Employee['EmployeeID'] = AC_Employee['EmployeeID'].apply(lambda x: f'AC_{x}')\n",
    "\n",
    "# maar dan ook prefix zetten in bijbehorende dimensies en tabellen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Employee tabel samenvoegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmployeeID                  object\n",
      "FirstName                   object\n",
      "LastName                    object\n",
      "Region                      object\n",
      "Country                     object\n",
      "State                       object\n",
      "City                        object\n",
      "PostalCode                  object\n",
      "Address                     object\n",
      "DepartmentID                object\n",
      "Job_title                   object\n",
      "Birth_date                  object\n",
      "Hire_date           datetime64[ns]\n",
      "Years_in_Service             int64\n",
      "Gender                      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Zorg ervoor dat alle vereiste kolommen bestaan en selecteer ze\n",
    "required_columns = ['EmployeeID', 'FirstName', 'LastName', 'Region', 'Country', 'State', 'City', 'PostalCode', 'Address', 'DepartmentID', 'Job_title', 'Birth_date', 'Hire_date', 'Years_in_Service', 'Gender']\n",
    "\n",
    "\n",
    "for col in required_columns:\n",
    "    if col not in AW_Employee.columns:\n",
    "        AW_Employee[col] = None\n",
    "    if col not in NW_Employee.columns:\n",
    "        NW_Employee[col] = None\n",
    "    if col not in AC_Employee.columns:\n",
    "        AC_Employee[col] = None\n",
    "\n",
    "# Selecteer de kolommen in de juiste volgorde\n",
    "AW_Employee = AW_Employee[required_columns]\n",
    "NW_Employee = NW_Employee[required_columns]\n",
    "AC_Employee = AC_Employee[required_columns]\n",
    "\n",
    "# Combineer de dataframes\n",
    "Employee = pd.concat([AW_Employee, NW_Employee, AC_Employee], ignore_index=True)\n",
    "\n",
    "# Toon het resultaat\n",
    "#print the colom types van employee\n",
    "\n",
    "print(Employee.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "employee Years in service kolom maken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns 'birth_date' and/or 'start_date' are missing in the DataFrame\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure correct data types and formats\n",
    "if 'birth_date' in Employee.columns and 'start_date' in Employee.columns:\n",
    "    Employee['birth_date'] = pd.to_datetime(Employee['birth_date'], errors='coerce')\n",
    "    Employee['start_date'] = pd.to_datetime(Employee['start_date'], errors='coerce')\n",
    "else:\n",
    "    print(\"Columns 'birth_date' and/or 'start_date' are missing in the DataFrame\")\n",
    "\n",
    "# Insert data into the table\n",
    "for index, row in Employee.iterrows():\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        INSERT INTO [Employee] (EmployeeID, FirstName, LastName, Region, Country, State, City, PostalCode, Address, DepartmentID, Job_title, Birth_date, Hire_date, Years_in_Service, Gender)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\"\n",
    "        params = (\n",
    "            row['EmployeeID'] if pd.notnull(row['EmployeeID']) else None,\n",
    "            row['FirstName'] if pd.notnull(row['FirstName']) else None,\n",
    "            row['LastName'] if pd.notnull(row['LastName']) else None,\n",
    "            row['Region'] if pd.notnull(row['Region']) else None,\n",
    "            row['Country'] if pd.notnull(row['Country']) else None,\n",
    "            row['State'] if pd.notnull(row['State']) else None,\n",
    "            row['City'] if pd.notnull(row['City']) else None,\n",
    "            row['PostalCode'] if pd.notnull(row['PostalCode']) else None,\n",
    "            row['Address'] if pd.notnull(row['Address']) else None,\n",
    "            int(row['DepartmentID']) if pd.notnull(row['DepartmentID']) else None,\n",
    "            row['Job_title'] if pd.notnull(row['Job_title']) else None,\n",
    "            row['Birth_date'] if pd.notnull(row['Birth_date']) else None,\n",
    "            row['Hire_date'] if pd.notnull(row['Hire_date']) else None,\n",
    "            row['Years_in_Service'] if pd.notnull(row['Years_in_Service']) else None,\n",
    "            row['Gender'] if pd.notnull(row['Gender']) else None\n",
    "            \n",
    "        )\n",
    "        export_cursor.execute(query, params)\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(query)\n",
    "        print(\"Parameters:\", params)\n",
    "\n",
    "export_conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data_mutatie simuleren**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge data into Employee table\n",
    "def merge_employee(employee_id, first_name, last_name, region, country, state, city, postal_code, address, department_id, job_title, birth_date, hire_date, years_in_service, gender):\n",
    "    merge_query = \"{CALL MergeEmployee (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)}\"\n",
    "    export_cursor.execute(merge_query, (employee_id, first_name, last_name, region, country, state, city, postal_code, address, department_id, job_title, birth_date, hire_date, years_in_service, gender))\n",
    "    export_conn.commit()\n",
    "    print(\"Merged into Employee table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Merge into Employee table\n",
    "    merge_employee('E123', 'John', 'Smith', 'Region1', 'Country1', 'State1', 'City1', '12345', '123 Main St', 101, 'Manager', '1980-01-01', '2010-01-01', 14, 'M')\n",
    "    merge_employee('E123', 'John', 'Doe', 'Region1', 'Country1', 'State1', 'City1', '12345', '123 Main St', 102, 'Senior Manager', '1980-01-01', '2010-01-01', 14, 'M')\n",
    "    merge_employee('AC_1751', 'John', 'Doe', 'Region1', 'Country1', 'State1', 'City1', '12345', '123 Main St', 102, 'Senior Manager', '1980-01-01', '2010-01-01', 14, 'M')\n",
    "\n",
    "\n",
    "finally:\n",
    "    # Close the connection\n",
    "    print(\"Connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uo-bedrijf-hqdop-DQ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
